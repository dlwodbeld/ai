{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day13.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNTzmoxIrC+qU6MJ4K+LJ1x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlwodbeld/ai/blob/main/Day13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "FJ-faJ4DAAq8",
        "outputId": "aea34275-eb48-4197-c3b3-6c2f57745f78"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-0a4096a1cabc>\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    X_data = df.loc([:,'petal_length':'petal_width'])\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "#Machine Learning 2\n",
        "\n",
        "#앙상블 모델 ensemble model -voting\n",
        "#여러 모듈을 결합하여 성능 높이는 방법이다.\n",
        "#voting 은 여러개의 모델이 예측한값중에서 다수결로 최종 결과를 정한다.\n",
        "#단, 앙상블 학습을 하게되면 개별모델에 비해 학습 시간이 오래걸리는 단점이있다.\n",
        "\n",
        "import pandas as pd #데이터 분석 모듈\n",
        "import numpy as np #데이터 계산 모듈\n",
        "\n",
        "from sklearn import datasets #머신러닝 관련 모듈\n",
        "iris = datasets.load_iris()\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.DataFrame(iris['data'], columns = iris['feature_names'])\n",
        "X_data = df.loc[:,'petal_length':'petal_width']\n",
        "y_data = df.loc[:,'target']\n",
        "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data, test_size=0.2,suffle=True,random_state = 20)\n",
        "knn = KNeighborsClassifier(n_neighbors = 7)\n",
        "svc = SVC(kernel='rbf')\n",
        "dtc =DecisionTreeClassifier(max_depth = 3, random_state=20)\n",
        "hvc = VotingClassifier(estimators = [('KNN',knn),('SVM',svc),('DT',dtc)], voting = 'hard')\n",
        "\n",
        "#학습\n",
        "hvc.fit(X_train,y_train)\n",
        "\n",
        "#예측\n",
        "y_hvc_pred = hvc.predict(X_test)\n",
        "\n",
        "#평가\n",
        "hvc_acc = accuracy_score(y_test,y_hvc_pred)\n",
        "hvc_acc "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#앙상블 모델 ensemble model -bagging\n",
        "\n",
        "#Decision Tree 는 한개의 트리를 사용한다. 여러개의 트리를 사용하여 각 모델의 개별예측 값을 코팅을 통해 결정한다.\n",
        "#이처럼 같으 알고리즘 모델을여러번 돌려 예측하는 방법을 bagging이라고한다.\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc = RandomForestClassifier(n_estimators=50,max_depth=3,random_state=20)\n",
        "\n",
        "#학습\n",
        "rfc.fit(X_train,y_train)\n",
        "#예측\n",
        "y_rfc_red = rfc.predict(X_test)\n",
        "#평가\n",
        "rfc_acc = accurcy_score(y_test,y_rfc_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "EZFpiS75PLEz",
        "outputId": "b6023d71-1ff5-4808-f048-2565ed5c2dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8b8090b77f00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0my_rfc_red\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import access\n",
        "#앙상블 모델 ensemble model - boosting\n",
        "#부스팅은 여러개의 약한 학습기(가벼운모델)를 순차적으로 학습한다.\n",
        "#잘못 예측한 데이터에 대한예측 오차를 줄이는 방향으로 모델을 계속 업데이트한다.\n",
        "#여러 모델을 동시에 학습하지않고 순서대로 학습하는 점에서 배깅과는 다르다.\n",
        "!pip install xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgbc = XGBClassifier(n_estimators = 50,max_depth = 3, random_state=20)\n",
        "\n",
        "#학습\n",
        "xgbc.fit(X_train,y_train)\n",
        "\n",
        "#예측\n",
        "y_hvc_pred = xgbc.redoct(X_test)\n",
        "\n",
        "#평가\n",
        "xgbc_acc = accuracy_score(y_test,y_xgbc_pred)\n",
        "xgbc_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "vbNjLLKgRysP",
        "outputId": "793574a7-e33c-46b8-ba43-2f6503f61427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.5)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-3426fb9e828c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#학습\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mxgbc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#과대 적합 overfitting & 과소적합 underfitting\n",
        "\n",
        "#과소적합 underfitting - 머신러닝을 진행할 때 학습 시킬 데이터가 현저히 적을떄 예측력이 떨어지는 증상\n",
        "\n",
        "#과대 적합 overfitting - 학습 시킨 데이터와 비슷한 것은 예측력이 우수하게 판단하지만 새로운데이터에는 예측력이 떨어지는 증상.\n",
        "\n",
        "#solution : 데이터양을 엄청나게 늘린다."
      ],
      "metadata": {
        "id": "S93VIto7Tj58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.common import random_state\n",
        "#k-fold 교차검증\n",
        "# 데이터 셋을 5개의 Fold로 분할\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = kFold(n_splits = 5, shuffle=True , random_state=20)\n",
        "\n",
        "#훈련용 데이터와 검증용 데이터의 행 인덱스를 각각의 Fold별로 구분하여 확인해보자.\n",
        "\n",
        "num_fold = 1\n",
        "\n",
        "for tr_idx,val_idx in kfold.split(X_train):\n",
        "  print('%s Fold-------------------------------------------------------------' % num_fold)\n",
        "  print('훈련 :',len(tr_idx),tr_idx[:10])\n",
        "  print('검증 :', len(val_idx),val_idx[:10])\n",
        "  num_fold = num_fold + 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "qFl9s0hSXR2_",
        "outputId": "34557dcf-5111-44ab-a4aa-18cbb08627b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-eed7e1f36988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# 데이터 셋을 5개의 Fold로 분할\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#훈련용 데이터와 검증용 데이터의 행 인덱스를 각각의 Fold별로 구분하여 확인해보자.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kFold' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련용 데이터와 검증용 데이터의 행 인덱스를 각 fold별로 구분하여 생성\n",
        "\n",
        "val_scores = [] # 5번의 예측 정확도를 담을 리스트\n",
        "\n",
        "num_fold = 1\n",
        "\n",
        "for tr_idx ,val_idx in kfold.split(X_train,y_train):\n",
        "#훈련용 데이터와 검증용 데이터를 행 인덱스 기준으로 추출\n",
        "  X_tr,X_val = X_train.iloc[tr_idx, :],X_train.iloc[val_idx, :] #X문제지\n",
        "  y_tr,y_val = y_train.iloc[tr_idx],y_train.iloc[val_idx] #Y답안지\n",
        "\n",
        "  #학습\n",
        "  rfc = RandomForestClassifier(max_depth=5,random_state=20)\n",
        "  rfc.fit(X_tr,y_tr)\n",
        "\n",
        "  #예측\n",
        "  y_val_pred = rfc.predict(X_val)\n",
        "\n",
        "  #검증\n",
        "  val_acc = accuracy_score(y_val,y_val_pred)\n",
        "\n",
        "  #결과 출력\n",
        "  print('%d Fold Accuracy : %.4f' % (num_fold,val_acc)) #각각의 폴드마다의 정확도\n",
        "  val_scores.append(val_acc)\n",
        "  num_fold += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "j7h-JO_ld5Qf",
        "outputId": "96f333ca-c398-4e7b-fcf6-2c500bde0186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c639af7c7827>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_fold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtr_idx\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mval_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m#훈련용 데이터와 검증용 데이터를 행 인덱스 기준으로 추출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mX_tr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#X문제지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kfold' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#평균 정확도 계산\n",
        "\n",
        "mean_score = np.mean(val_scores)\n",
        "\n",
        "print('평균 정확도 : ' ,np.round(mean_score,2)* 100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpvjZte7g_Uw",
        "outputId": "9327cc7f-1765-4c26-e82c-4abc53de5bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "평균 정확도 :  nan %\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    }
  ]
}